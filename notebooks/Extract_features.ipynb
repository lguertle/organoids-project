{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacfa60d",
   "metadata": {},
   "source": [
    "# PIPELINE OF FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcc21b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s05_no_stack.jpg', 's06_no_stack.jpg', 's07_no_stack.jpg', 's08_no_stack.jpg', 's05.jpg', 's06.jpg', 's07.jpg', 's08.jpg', 's03_no_stack.jpg', 's04_no_stack.jpg', 's12.jpg', 's13.jpg', 's14.jpg', 's12_no_stack.jpg', 's13_no_stack.jpg', 's14_no_stack.jpg', 's09_no_stack.jpg', 's09.jpg', 's19.jpg']\n",
      "s05_no_stack.jpg\n",
      "s06_no_stack.jpg\n",
      "s07_no_stack.jpg\n",
      "s08_no_stack.jpg\n",
      "s05.jpg\n",
      "s06.jpg\n",
      "s07.jpg\n",
      "s08.jpg\n",
      "s03_no_stack.jpg\n",
      "s04_no_stack.jpg\n",
      "s12.jpg\n",
      "s13.jpg\n",
      "s14.jpg\n",
      "s12_no_stack.jpg\n",
      "s13_no_stack.jpg\n",
      "s14_no_stack.jpg\n",
      "s09_no_stack.jpg\n",
      "s09.jpg\n",
      "s19.jpg\n",
      "['s13.jpg', 's14.jpg', 's15.jpg', 's17.jpg', 's19.jpg', 's20.jpg', 's21.jpg', 's22.jpg', 's23.jpg', 's24.jpg']\n",
      "s13.jpg\n",
      "s14.jpg\n",
      "s15.jpg\n",
      "s17.jpg\n",
      "s19.jpg\n",
      "s20.jpg\n",
      "s21.jpg\n",
      "s22.jpg\n",
      "s23.jpg\n",
      "s24.jpg\n",
      "['s03.jpg', 's04.jpg', 's05.jpg', 's08.jpg', 's07.jpg', 's06.jpg', 's17.jpg', 's16.jpg', 's12.jpg', 's13.jpg', 's18.jpg', 's19.jpg', 's02_no_stack.jpg', 's06_no_stack.jpg', 's09.jpg', 's03_no_stack.jpg', 's04 (2).jpg', 's05 (2).jpg', 's06 (2).jpg', 's08 (2).jpg', 's12 (2).jpg', 's13 (2).jpg']\n",
      "s03.jpg\n",
      "s04.jpg\n",
      "s05.jpg\n",
      "s08.jpg\n",
      "s07.jpg\n",
      "s06.jpg\n",
      "s17.jpg\n",
      "s16.jpg\n",
      "s12.jpg\n",
      "s13.jpg\n",
      "s18.jpg\n",
      "s19.jpg\n",
      "s02_no_stack.jpg\n",
      "s06_no_stack.jpg\n",
      "s09.jpg\n",
      "s03_no_stack.jpg\n",
      "s04 (2).jpg\n",
      "s05 (2).jpg\n",
      "s06 (2).jpg\n",
      "s08 (2).jpg\n",
      "s12 (2).jpg\n",
      "s13 (2).jpg\n",
      "['s07_no_stack.jpg', 's08_no_stack.jpg', 's09_no_stack.jpg', 's10_no_stack.jpg', 's15.jpg', 's11.jpg', 's06_no_stack.jpg', 's17_no_stack.jpg', 's18_no_stack.jpg', 's19_no_stack.jpg', 's03.jpg', 's14_no_stack.jpg', 's15_no_stack.jpg', 's16_no_stack.jpg', 's01_no_stack.jpg']\n",
      "['s07.jpg', 's08.jpg', 's13.jpg', 's14.jpg', 's09.jpg', 's10.jpg', 's11.jpg', 's09_no_stack.jpg', 's10_no_stack.jpg', 's11_no_stack.jpg', 's18.jpg', 's19.jpg', 's20.jpg', 's12.jpg', 's16_no_stack.jpg', 's15.jpg', 's16.jpg', 's17.jpg', 's12_no_stack.jpg', 's01.jpg', 's02.jpg', 's03.jpg', 's04_no_stack.jpg', 's13_no_stack.jpg', 's01 (2).jpg', 's02 (2).jpg', 's11_no_stack (2).jpg', 's12_no_stack (2).jpg']\n",
      "['s04.jpg', 's05.jpg', 's06.jpg', 's07.jpg', 's08.jpg', 's13_no_stack.jpg', 's14_no_stack.jpg', 's15_no_stack.jpg', 's17_no_stack.jpg', 's18_no_stack.jpg', 's19_no_stack.jpg', 's20_no_stack.jpg', 's21_no_stack.jpg', 's22_no_stack.jpg', 's23_no_stack.jpg', 's24_no_stack.jpg', 's13.jpg', 's14.jpg', 's15.jpg', 's17.jpg', 's18.jpg', 's16.jpg', 's19.jpg', 's03.jpg']\n",
      "['s09.jpg', 's10.jpg', 's11.jpg', 's18.jpg', 's19.jpg', 's20.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "from cellpose import models\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from matplotlib import colors\n",
    "from importlib import reload\n",
    "import utility\n",
    "reload(utility)\n",
    "from utility import get_hard_disk_path, compute_big_cell_labels, compute_small_cell_labels, calculate_closest_boundary_distances\n",
    "\n",
    "initial_path = r\"E:\\data_for_seg\\\\\"\n",
    "all_labels = [\"keep2\", \"reseed1\", \"split\", \"empty\", \"keep0\", \"keep1\", \"reseed0\"]\n",
    "labels_big_cell = [\"dead\", \"keep2\", \"reseed1\", \"split\"]\n",
    "labels_small_cell = [\"empty\", \"keep0\", \"keep1\", \"reseed0\"]\n",
    "properties_list = ['area', 'mean_intensity', 'solidity', 'convex_area', 'equivalent_diameter', 'perimeter', 'extent', 'max_intensity', 'min_intensity', 'eccentricity']\n",
    "output_csv = initial_path + \"statistics_features_IP.csv\"  # Adjust the output file name\n",
    "\n",
    "def compute_feature_statistics(data, output_csv, properties_list):\n",
    "    statistics = {}\n",
    "\n",
    "    other_features = {\n",
    "        \"image_name\": data[\"image_name\"].iloc[0],  # Assuming 'image_name' is the same for all rows in data\n",
    "        \"label\": data[\"label\"].iloc[0],  # Assuming 'label' is the same for all rows in data\n",
    "        \"count\": data[\"sample\"].max(),\n",
    "        \"occupancy\": data[\"occupancy\"],\n",
    "        #\"density\": data[\"density\"]\n",
    "    }\n",
    "    statistics.update(other_features)\n",
    "\n",
    "    for column_name in properties_list:\n",
    "        if column_name in data.columns:\n",
    "            column = data[column_name]\n",
    "\n",
    "            # Calculate statistics for the current column\n",
    "            mean_value = column.mean()\n",
    "            sd_value = column.std()\n",
    "            q1_value = column.quantile(0.25)  # 25% Quartile\n",
    "            median_value = column.quantile(0.50)  # 50% Quartile or Median\n",
    "            q3_value = column.quantile(0.75)  # 75% Quartile\n",
    "\n",
    "            # Add the statistics to the row dictionary\n",
    "            statistics.update({\n",
    "                f\"{column_name}_Mean\": mean_value,\n",
    "                f\"{column_name}_StdDev\": sd_value,\n",
    "                f\"{column_name}_Q1\": q1_value,\n",
    "                f\"{column_name}_Median\": median_value,\n",
    "                f\"{column_name}_Q3\": q3_value,\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the dictionary\n",
    "    statistics_df = pd.DataFrame(statistics, index=[0])\n",
    "\n",
    "    # Save the DataFrame to the output CSV file\n",
    "    statistics_df.to_csv(output_csv, mode='a', header=not os.path.isfile(output_csv), index=False)\n",
    "\n",
    "def compute_occupancy(labels, image):\n",
    "    \"\"\"\n",
    "    Compute the occupancy of cells in the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - labels: labeled image\n",
    "    - image: original grayscale image\n",
    "    \n",
    "    Returns:\n",
    "    - occupancy: ratio of cell area to total image area\n",
    "    \"\"\"\n",
    "    cell_area = np.sum(labels > 0)  # Total number of pixels occupied by cells\n",
    "    image_area = image.size         # Total number of pixels in the image\n",
    "    return cell_area / image_area\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    os.remove(output_csv)\n",
    "\n",
    "if not os.path.exists(initial_path + \"labeled/\"):\n",
    "    os.makedirs(initial_path + \"labeled/\")\n",
    "\n",
    "for label in all_labels:\n",
    "    label_path = os.path.join(initial_path + \"labeled\", label)\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    if not os.path.exists(os.path.join(label_path, \"IP_pipeline\")):\n",
    "        os.mkdir(os.path.join(label_path, \"IP_pipeline\"))\n",
    "    os.chdir(os.path.join(initial_path + \"z_projection\", label))\n",
    "    files = [file for file in os.listdir() if \"Simple\" not in file and \"filled\" not in file]\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        if \"Simple\" or \"filled\" not in file:\n",
    "            image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            if label in labels_big_cell:\n",
    "                print(file)\n",
    "                labels = compute_big_cell_labels(image)\n",
    "            elif label in labels_small_cell:\n",
    "                labels = compute_small_cell_labels(image)\n",
    "            # Generate a colormap for labels\n",
    "            label_cmap = colors.ListedColormap(np.random.rand(labels.max() + 1, 3))\n",
    "\n",
    "            # Create a colored label image\n",
    "            colored_label_image = label_cmap(labels)\n",
    "\n",
    "            # Convert to uint8 format (0-255)\n",
    "            colored_label_image = (colored_label_image * 255).astype(np.uint8)\n",
    "\n",
    "            output_path = os.path.join(label_path, \"IP_pipeline\", file)\n",
    "            if not os.path.exists(output_path):\n",
    "                cv2.imwrite(output_path, cv2.cvtColor(colored_label_image, cv2.COLOR_RGBA2BGRA))\n",
    "\n",
    "            info_table = pd.DataFrame(\n",
    "                measure.regionprops_table(\n",
    "                    labels,\n",
    "                    intensity_image=image,\n",
    "                    properties=['label', 'area', 'mean_intensity', 'solidity', 'convex_area', 'equivalent_diameter', 'perimeter', 'extent', 'max_intensity', 'min_intensity', 'eccentricity'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            occupancy = compute_occupancy(labels, image)\n",
    "            #density = calculate_closest_boundary_distances(labels)\n",
    "            #info_table['density'] = density\n",
    "            info_table['occupancy'] = occupancy  # Add the occupancy to the statistics\n",
    "            info_table = info_table.rename(columns={\"label\": \"sample\"})\n",
    "            info_table['label'] = label\n",
    "            info_table['image_name'] = file\n",
    "\n",
    "            compute_feature_statistics(info_table, output_csv, properties_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe803f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from E:/data_for_seg/\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s09.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s11_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s12_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s12.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s13_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s13.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s01.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s02_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s02.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s03_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s03.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s04_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s04.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s05.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s06_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s06.jpg\n",
      "E:/data_for_seg/z_projection\\dead\\filled_cleaned\\original_files\\s08.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s14_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s14.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s19.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s03_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s04_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s05_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s05.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s06_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s06.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s07_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s07.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s08_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s08.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s09_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s09.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s12_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s12.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s13_no_stack.jpg\n",
      "E:/data_for_seg/z_projection\\keep2\\filled_cleaned\\original_files\\s13.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s21.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s22.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s23.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s24.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s13.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s14.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s15.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s17.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s19.jpg\n",
      "E:/data_for_seg/z_projection\\reseed1\\filled_cleaned\\original_files\\s20.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s13.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s16.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s17.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s18.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s19.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s03.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s04.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s05.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s06.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s07.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s08.jpg\n",
      "E:/data_for_seg/z_projection\\split\\filled_cleaned\\original_files\\s12.jpg\n",
      "s07_no_stack.jpg\n",
      "s08_no_stack.jpg\n",
      "s09_no_stack.jpg\n",
      "s10_no_stack.jpg\n",
      "s15.jpg\n",
      "s11.jpg\n",
      "s06_no_stack.jpg\n",
      "s17_no_stack.jpg\n",
      "s18_no_stack.jpg\n",
      "s19_no_stack.jpg\n",
      "s03.jpg\n",
      "s14_no_stack.jpg\n",
      "s15_no_stack.jpg\n",
      "s16_no_stack.jpg\n",
      "s01_no_stack.jpg\n",
      "s07.jpg\n",
      "s08.jpg\n",
      "s13.jpg\n",
      "s14.jpg\n",
      "s09.jpg\n",
      "s10.jpg\n",
      "s11.jpg\n",
      "s09_no_stack.jpg\n",
      "s10_no_stack.jpg\n",
      "s11_no_stack.jpg\n",
      "s18.jpg\n",
      "s19.jpg\n",
      "s20.jpg\n",
      "s12.jpg\n",
      "s16_no_stack.jpg\n",
      "s15.jpg\n",
      "s16.jpg\n",
      "s17.jpg\n",
      "s12_no_stack.jpg\n",
      "s01.jpg\n",
      "s02.jpg\n",
      "s04.jpg\n",
      "s05.jpg\n",
      "s06.jpg\n",
      "s07.jpg\n",
      "s08.jpg\n",
      "s13_no_stack.jpg\n",
      "s14_no_stack.jpg\n",
      "s15_no_stack.jpg\n",
      "s17_no_stack.jpg\n",
      "s18_no_stack.jpg\n",
      "s19_no_stack.jpg\n",
      "s20_no_stack.jpg\n",
      "s21_no_stack.jpg\n",
      "s22_no_stack.jpg\n",
      "s23_no_stack.jpg\n",
      "s24_no_stack.jpg\n",
      "s13.jpg\n",
      "s14.jpg\n",
      "s15.jpg\n",
      "s17.jpg\n",
      "s18.jpg\n",
      "s16.jpg\n",
      "s19.jpg\n",
      "s03.jpg\n",
      "s09.jpg\n",
      "s10.jpg\n",
      "s11.jpg\n",
      "s18.jpg\n",
      "s19.jpg\n",
      "s20.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "from cellpose import models\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from matplotlib import colors\n",
    "from importlib import reload\n",
    "import utility\n",
    "reload(utility)\n",
    "from utility import get_hard_disk_path, compute_big_cell_labels, compute_small_cell_labels, calculate_closest_boundary_distances\n",
    "\n",
    "initial_path = r\"E:\\data_for_seg\\\\\"\n",
    "all_labels = [\"keep2\", \"reseed1\", \"split\", \"empty\", \"keep0\", \"keep1\", \"reseed0\"]\n",
    "labels_big_cell = [\"dead\", \"keep2\", \"reseed1\", \"split\"]\n",
    "labels_small_cell = [\"empty\", \"keep0\", \"keep1\", \"reseed0\"]\n",
    "properties_list = ['area', 'mean_intensity', 'solidity', 'convex_area', 'equivalent_diameter', 'perimeter', 'extent', 'max_intensity', 'min_intensity', 'eccentricity']\n",
    "output_csv = initial_path + \"statistics_features_ilastik.csv\"  # Adjust the output file name\n",
    "\n",
    "# --------------------\n",
    "# ALL FUNCTIONS\n",
    "# --------------------\n",
    "\n",
    "def compute_feature_statistics(data, output_csv, properties_list):\n",
    "    statistics = {}\n",
    "\n",
    "    other_features = {\n",
    "        \"image_name\": data[\"image_name\"].iloc[0],  # Assuming 'image_name' is the same for all rows in data\n",
    "        \"label\": data[\"label\"].iloc[0],  # Assuming 'label' is the same for all rows in data\n",
    "        \"count\": data[\"sample\"].max(),\n",
    "        \"occupancy\": data[\"occupancy\"],\n",
    "        #\"density\": data[\"density\"]\n",
    "    }\n",
    "    statistics.update(other_features)\n",
    "\n",
    "    for column_name in properties_list:\n",
    "        if column_name in data.columns:\n",
    "            column = data[column_name]\n",
    "\n",
    "            # Calculate statistics for the current column\n",
    "            mean_value = column.mean()\n",
    "            sd_value = column.std()\n",
    "            min_value = column.min()\n",
    "            max_value = column.max()\n",
    "\n",
    "            # Add the statistics to the row dictionary\n",
    "            statistics.update({\n",
    "                f\"{column_name}_Mean\": mean_value,\n",
    "                f\"{column_name}_StdDev\": sd_value,\n",
    "                f\"{column_name}_Min\": min_value,\n",
    "                f\"{column_name}_Max\": max_value,\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the dictionary\n",
    "    statistics_df = pd.DataFrame(statistics, index=[0])\n",
    "\n",
    "    # Save the DataFrame to the output CSV file\n",
    "    statistics_df.to_csv(output_csv, mode='a', header=not os.path.isfile(output_csv), index=False)\n",
    "\n",
    "def compute_occupancy(labels, image):\n",
    "    \"\"\"\n",
    "    Compute the occupancy of cells in the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - labels: labeled image\n",
    "    - image: original grayscale image\n",
    "    \n",
    "    Returns:\n",
    "    - occupancy: ratio of cell area to total image area\n",
    "    \"\"\"\n",
    "    cell_area = np.sum(labels > 0)  # Total number of pixels occupied by cells\n",
    "    image_area = image.size         # Total number of pixels in the image\n",
    "    return cell_area / image_area\n",
    "\n",
    "def extract_features(labels, output_path, image_path):\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    print(image_path)\n",
    "    # Generate a colormap for labels\n",
    "    label_cmap = colors.ListedColormap(np.random.rand(labels.max() + 1, 3))\n",
    "\n",
    "    # Create a colored label image\n",
    "    colored_label_image = label_cmap(labels)\n",
    "\n",
    "    # Convert to uint8 format (0-255)\n",
    "    colored_label_image = (colored_label_image * 255).astype(np.uint8)\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(colored_label_image, cv2.COLOR_RGBA2BGRA))\n",
    "\n",
    "    info_table = pd.DataFrame(\n",
    "        measure.regionprops_table(\n",
    "            labels,\n",
    "            intensity_image=image,\n",
    "            properties=['label', 'area', 'mean_intensity', 'solidity', 'convex_area', 'equivalent_diameter', 'perimeter', 'extent', 'max_intensity', 'min_intensity', 'eccentricity'],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    occupancy = compute_occupancy(labels, image)\n",
    "    #density = calculate_closest_boundary_distances(labels)\n",
    "    #info_table['density'] = density\n",
    "    info_table['occupancy'] = occupancy  # Add the occupancy to the statistics\n",
    "    info_table = info_table.rename(columns={\"label\": \"sample\"})\n",
    "    info_table['label'] = label\n",
    "    info_table['image_name'] = os.path.basename(image_path)\n",
    "\n",
    "    compute_feature_statistics(info_table, output_csv, properties_list)\n",
    "\n",
    "# --------------------\n",
    "# MAIN\n",
    "# --------------------\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    os.remove(output_csv)\n",
    "\n",
    "if not os.path.exists(initial_path + \"labeled/\"):\n",
    "    os.makedirs(initial_path + \"labeled/\")\n",
    "    \n",
    "\n",
    "for label in all_labels:\n",
    "    label_path = os.path.join(initial_path + \"labeled\", label)\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    os.chdir(os.path.join(initial_path + \"z_projection\", label))\n",
    "    if not os.path.exists(os.path.join(label_path, \"Ilastik_pipeline\")):\n",
    "        os.mkdir(os.path.join(label_path, \"Ilastik_pipeline\"))\n",
    "    files = os.listdir()\n",
    "    if not os.path.exists(\"filled_cleaned\"):\n",
    "        for file in files:\n",
    "            if \"Simple\" not in file:\n",
    "                image_path = file\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                labels = compute_small_cell_labels(image)\n",
    "                output_path = os.path.join(label_path, \"Ilastik_pipeline\", file)\n",
    "                extract_features(labels, output_path, image_path)\n",
    "    elif os.path.exists(os.path.join(initial_path, \"z_projection\", label, \"filled_cleaned\")):\n",
    "        # Define the directory for filled_cleaned files and original_files\n",
    "        filled_cleaned_dir = os.path.join(initial_path, \"z_projection\", label, \"filled_cleaned\")\n",
    "        original_files_dir = os.path.join(filled_cleaned_dir, \"original_files\")\n",
    "\n",
    "        # Get a list of files in filled_cleaned directory\n",
    "        filled_cleaned_files = os.listdir(filled_cleaned_dir)\n",
    "\n",
    "        for file in filled_cleaned_files:\n",
    "            if \"labeled_filled\" in file:\n",
    "\n",
    "                # Read the labels file using the full path\n",
    "                labels_path = os.path.join(filled_cleaned_dir, file)\n",
    "                labels = cv2.imread(labels_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                # Check if the labels were read successfully\n",
    "                if labels is None:\n",
    "                    print(f\"Failed to read labels from {labels_path}\")\n",
    "                    continue\n",
    "\n",
    "                labels = labels.astype(int)\n",
    "\n",
    "                # Create the output path for labeled_cleaned files\n",
    "                output_path = os.path.join(label_path, \"Ilastik_pipeline\", file)\n",
    "\n",
    "                image_path = os.path.join(original_files_dir, file[15:-24] + \".jpg\")\n",
    "\n",
    "                # Check if the image was read successfully\n",
    "                if image is None:\n",
    "                    print(f\"Failed to read image from {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Now you can extract features with the correct image and labels\n",
    "                extract_features(labels, output_path, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b4788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "organoids-project",
   "language": "python",
   "name": "organoids-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
